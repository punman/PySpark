from pyspark import SparkConf,SparkContext
import re
import collections

conf = SparkConf().setMaster('local').setAppName('CountWord')
sc = SparkContext(conf=conf)

def norword(text):
    return re.compile(r'\W+',re.UNICODE).split(text.lower())

input = sc.textFile('c:/SparkCourse/Book.txt')
words = input.flatMap(norword)
wordcounts = words.map(lambda x: (x,1)).reduceByKey(lambda x,y: x+y)
wordsorted=wordcounts.map(lambda (x,y): (y,x)).sortByKey()
result=wordsorted.collect()

for i in result:
    count=str(i[0])
    cleanword=i[1].encode('ascii','ignore')
    if(cleanword):
        print(cleanword+': '+count)
